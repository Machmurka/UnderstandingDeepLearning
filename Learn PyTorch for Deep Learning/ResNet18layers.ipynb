{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import  DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from typing import Tuple, Dict, List\n",
    "from PIL import Image\n",
    "# https://medium.com/@karuneshu21/resnet-paper-walkthrough-b7f3bdba55f0\n",
    "# https://arxiv.org/pdf/1512.03385.pdf\n",
    "# https://medium.com/@karuneshu21/how-to-resnet-in-pytorch-9acb01f36cf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderCustom(Dataset):\n",
    "    \n",
    "    # 2. Initialize with a targ_dir and transform (optional) parameter\n",
    "    def __init__(self, targ_dir: str, transform=None) -> None:\n",
    "        \n",
    "        # 3. Create class attributes\n",
    "        # Get all image paths\n",
    "        self.paths = list(Path(targ_dir).glob(\"*/*.jpg\")) # note: you'd have to update this if you've got .png's or .jpeg's\n",
    "        # Setup transforms\n",
    "        self.transform = transform\n",
    "        # Create classes and class_to_idx attributes\n",
    "        # print(self.paths)\n",
    "        self.classes, self.class_to_idx = self.find_classes(targ_dir)\n",
    "\n",
    "    # 4. Make function to load images\n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "        \"Opens an image via a path and returns it.\"\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path) \n",
    "    \n",
    "    # 5. Overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)\n",
    "    def __len__(self) -> int:\n",
    "        \"Returns the total number of samples.\"\n",
    "        return len(self.paths)\n",
    "    \n",
    "    # 6. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"Returns one sample of data, data and label (X, y).\"\n",
    "        img = self.load_image(index)\n",
    "        class_name  = self.paths[index].parent.name # expects path in data_folder/class_name/image.jpeg\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "        # Transform if necessary\n",
    "        if self.transform:\n",
    "            return self.transform(img), class_idx # return data, label (X, y)\n",
    "        else:\n",
    "            return img, class_idx # return data, label (X, y)\n",
    "        \n",
    "    def find_classes(self,directory:str)->Tuple[list[str],dict[str,int]]:\n",
    "        classes=sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "\n",
    "        if not classes:\n",
    "            raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
    "        \n",
    "        class_to_idx={cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        \n",
    "        print(classes,class_to_idx)\n",
    "        return classes,class_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataTest():\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        self.train_dir = \"C:\\\\Users\\\\Jakub Machura\\\\source\\\\repos\\\\UnderstandingDeepLearning\\\\data\\\\pizza_steak_sushi\\\\train\"\n",
    "        self.test_dir = \"C:\\\\Users\\\\Jakub Machura\\\\source\\\\repos\\\\UnderstandingDeepLearning\\\\data\\\\pizza_steak_sushi\\\\test\"\n",
    "        \"\"\"\n",
    "            temp placement for of transform\n",
    "        \"\"\"\n",
    "        self.train_transform=transforms.Compose([\n",
    "            transforms.Resize(size=(224,224)),\n",
    "            # transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "        self.test_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "        self.train_data_custom =ImageFolderCustom(self.train_dir,transform=self.train_transform)\n",
    "        self.test_data_custom=ImageFolderCustom(self.test_dir,transform=self.test_transforms)\n",
    "    \n",
    "        \"\"\"temp place for testing data\"\"\"    \n",
    "        # Check for equality amongst our custom Dataset and ImageFolder Dataset\n",
    "        # print((len(self.train_data_custom) == len(data.train_data)) & (len(self.test_data_custom) == len(data.test_data)))\n",
    "        # print(self.train_data_custom.classes == data.train_data.classes)\n",
    "        # print(self.train_data_custom.class_to_idx == data.train_data.class_to_idx)\n",
    "\n",
    "        self.IntoDataLoaders()\n",
    "\n",
    "    def IntoDataLoaders(self):\n",
    "        BATCH_SIZE=32\n",
    "        # NUM_WORKERS = os.cpu_count()\n",
    "        NUM_WORKERS = 1\n",
    "\n",
    "        # print(f\"number of workers avalible {NUM_WORKERS}\")\n",
    "        self.train_dataloader= DataLoader(dataset=self.train_data_custom, # use custom created train Dataset\n",
    "                                     batch_size=BATCH_SIZE, # how many samples per batch?\n",
    "                                    #  num_workers=NUM_WORKERS, # how many subprocesses to use for data loading? (higher = more)\n",
    "                                     shuffle=True) # shuffle the data?\n",
    "\n",
    "        self.test_dataloader = DataLoader(dataset=self.test_data_custom, # use custom created test Dataset\n",
    "                                    batch_size=BATCH_SIZE, \n",
    "                                    # num_workers=NUM_WORKERS, \n",
    "                                    shuffle=False) # don't usually need to shuffle testing data\n",
    "\n",
    "        img,label=next(iter(self.test_dataloader))\n",
    "        # print(f\"shape of custome dataloader img {img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self,in_channels,num_classes) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1=nn.Conv2d(in_channels,64,kernel_size=7,stride=2,padding=3)\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc=nn.Linear(512,num_classes)\n",
    "\n",
    "        self.in_channels=64\n",
    "        self.out_channels=64\n",
    "\n",
    "        # self.conv2=[]\n",
    "        # for i in range(layers[0]):\n",
    "        #     self.conv2.append(nn.Conv2d(self.in_channels,self.out_channels,kernel_size=3,padding=2,stride=1))\n",
    "        # self.bn2=nn.BatchNorm2d(self.out_channels)\n",
    "\n",
    "        self.conv2_1=nn.Conv2d(self.in_channels,self.out_channels,kernel_size=3,padding=1,stride=1)\n",
    "        self.bn2_1=nn.BatchNorm2d(self.out_channels)\n",
    "\n",
    "        self.out_channels=self.out_channels*2\n",
    "        self.conv3_1=nn.Conv2d(self.in_channels,self.out_channels,kernel_size=3,padding=1,stride=2)\n",
    "        self.bn3_1=nn.BatchNorm2d(self.out_channels)\n",
    "\n",
    "        self.in_channels=self.out_channels\n",
    "        self.out_channels=self.out_channels*2\n",
    "        self.conv4_1=nn.Conv2d(self.in_channels,self.out_channels,kernel_size=3,padding=1,stride=2)\n",
    "        self.bn4_1=nn.BatchNorm2d(self.out_channels)\n",
    "\n",
    "\n",
    "        self.in_channels=self.out_channels\n",
    "        self.out_channels=self.out_channels*2\n",
    "        self.conv5_1=nn.Conv2d(self.in_channels,self.out_channels,kernel_size=3,padding=1,stride=2)\n",
    "        self.bn5_1=nn.BatchNorm2d(self.out_channels)\n",
    "\n",
    "    def forward(self,x):\n",
    "       \n",
    "\n",
    "        x=self.conv1(x)\n",
    "        print(f\"after conv1 channels: 64 kernel_size: 7 stride: 2 padding: 3 {x.shape}\")\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        print(f\"after maxpool kernel_size: 3 stride: 2 padding: 1 {x.shape}\")\n",
    "        identity=x\n",
    "        x=self.conv2_1(x)\n",
    "        x=self.bn2_1(x)\n",
    "        x=self.relu(x)\n",
    "        x+=identity\n",
    "        print(f\"identity shape {identity.shape}\")\n",
    "        print(f\"after conv2 channels: 64 kernel_size: 3 stride: 1 padding: 1 {x.shape}\")\n",
    "\n",
    "\n",
    "        identity=x\n",
    "        x=self.conv3_1(x)\n",
    "        x=self.bn3_1(x)\n",
    "        x=self.relu(x)\n",
    "        identity_downsample=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=1,stride=2,padding=0),\n",
    "            nn.BatchNorm2d(num_features=128)\n",
    "        )\n",
    "        x+=identity_downsample(identity)\n",
    "        print(f\"identity shape {identity.shape}\")\n",
    "        print(f\"after conv3 channels: 128 kernel_size: 3 stride: 2 padding: 1 {x.shape}\")\n",
    "\n",
    "        \n",
    "        \n",
    "        identity=x\n",
    "        x=self.conv4_1(x)\n",
    "        x=self.bn4_1(x)\n",
    "        x=self.relu(x)\n",
    "        identity_downsample=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=1,stride=2,padding=0),\n",
    "            nn.BatchNorm2d(num_features=256)\n",
    "        )\n",
    "        x+=identity_downsample(identity)\n",
    "        print(f\"identity shape {identity.shape}\")\n",
    "        print(f\"after conv4 channels: 256 kernel_size: 3 stride: 2 padding: 1 {x.shape}\")\n",
    "        \n",
    "\n",
    "        identity=x\n",
    "        x=self.conv5_1(x)\n",
    "        x=self.bn5_1(x)\n",
    "        x=self.relu(x)\n",
    "        identity_downsample=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256,out_channels=512,kernel_size=1,stride=2,padding=0),\n",
    "            nn.BatchNorm2d(num_features=512)\n",
    "        )\n",
    "        x+=identity_downsample(identity)\n",
    "        print(f\"identity shape {identity.shape}\")\n",
    "        print(f\"after conv4 channels: 256 kernel_size: 3 stride: 2 padding: 1 {x.shape}\")\n",
    "        \n",
    "        x=self.avgpool(x)\n",
    "        print(f\"after avgpool {x.shape}\")\n",
    "        x=x.reshape(x.shape[0],-1)\n",
    "        print(f\"after reshape {x.shape}\")\n",
    "\n",
    "        x=self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    # def __make_layers(self,num_residual_block,out_channels,stride):\n",
    "        \n",
    "    #     layers=[]\n",
    "    #     for i in range(num_residual_block):\n",
    "    #         layers.append(nn.Conv2d(self.in_channels,out_channels,kernel_size=3,padding=2,stride=stride))\n",
    "        \n",
    "    #     return(nn.Sequential(*layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after conv1 channels: 64 kernel_size: 7 stride: 2 padding: 3 torch.Size([2, 64, 112, 112])\n",
      "after maxpool kernel_size: 3 stride: 2 padding: 1 torch.Size([2, 64, 56, 56])\n",
      "identity shape torch.Size([2, 64, 56, 56])\n",
      "after conv2 channels: 64 kernel_size: 3 stride: 1 padding: 1 torch.Size([2, 64, 56, 56])\n",
      "identity shape torch.Size([2, 64, 56, 56])\n",
      "after conv3 channels: 128 kernel_size: 3 stride: 2 padding: 1 torch.Size([2, 128, 28, 28])\n",
      "identity shape torch.Size([2, 128, 28, 28])\n",
      "after conv4 channels: 256 kernel_size: 3 stride: 2 padding: 1 torch.Size([2, 256, 14, 14])\n",
      "identity shape torch.Size([2, 256, 14, 14])\n",
      "after conv4 channels: 256 kernel_size: 3 stride: 2 padding: 1 torch.Size([2, 512, 7, 7])\n",
      "after avgpool torch.Size([2, 512, 1, 1])\n",
      "after reshape torch.Size([2, 512])\n",
      "out shape torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "net=ResNet(3,4)\n",
    "x=torch.randn(2,3,224,224)\n",
    "y=net(x)\n",
    "print(f\"out shape {y.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
